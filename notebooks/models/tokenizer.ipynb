{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T20:08:56.887146Z",
     "start_time": "2025-09-28T20:08:56.881890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def build_vocab():\n",
    "    \"\"\"\n",
    "    Build vocabulary for BoardGPT:\n",
    "    - 60 positions (8x8 board minus 4 starting squares for Othello)\n",
    "    - Special tokens <pad>, <bos>, <eos>\n",
    "    \"\"\"\n",
    "    # Generate all positions\n",
    "    positions = [f\"{c}{r}\" for c in \"abcdefgh\" for r in range(1, 9)]\n",
    "    # Remove the 4 starting squares (Othello)\n",
    "    for start in [\"d4\", \"e5\", \"d5\", \"e4\"]:\n",
    "        positions.remove(start)\n",
    "    # end for\n",
    "\n",
    "    specials = [\"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "    tokens = specials + positions\n",
    "\n",
    "    # Map tokens to integer IDs\n",
    "    vocab = {tok: i for i, tok in enumerate(tokens)}\n",
    "\n",
    "    # Save to vocab.json\n",
    "    with open(\"vocab.json\", \"w\") as f:\n",
    "        json.dump(vocab, f, indent=2)\n",
    "    # end with\n",
    "\n",
    "    return vocab\n",
    "# end def build_vocab"
   ],
   "id": "32f0dacdbedd959a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T20:16:01.281856Z",
     "start_time": "2025-09-28T20:16:01.277616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "\n",
    "def build_tokenizer(vocab: dict, save_path=\"tokenizer.json\"):\n",
    "    \"\"\"\n",
    "    Build a HuggingFace-compatible tokenizer from a fixed vocab.\n",
    "    Saves a tokenizer.json file that can be reloaded later.\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(WordLevel(vocab=vocab, unk_token=\"<pad>\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()  # ðŸ”‘ split on spaces\n",
    "    tokenizer.save(save_path)\n",
    "\n",
    "    fast_tok = PreTrainedTokenizerFast(\n",
    "        tokenizer_file=save_path,\n",
    "        bos_token=\"<bos>\",\n",
    "        eos_token=\"<eos>\",\n",
    "        pad_token=\"<pad>\",\n",
    "        unk_token=\"<pad>\",\n",
    "    )\n",
    "    return fast_tok"
   ],
   "id": "a8a75f5cda93e64f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T20:16:01.945071Z",
     "start_time": "2025-09-28T20:16:01.940136Z"
    }
   },
   "cell_type": "code",
   "source": "vocab = build_vocab()",
   "id": "d22bf1d9344e14c5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T20:16:02.724382Z",
     "start_time": "2025-09-28T20:16:02.718896Z"
    }
   },
   "cell_type": "code",
   "source": "vocab",
   "id": "54637c48bc649a4b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<bos>': 1,\n",
       " '<eos>': 2,\n",
       " 'a1': 3,\n",
       " 'a2': 4,\n",
       " 'a3': 5,\n",
       " 'a4': 6,\n",
       " 'a5': 7,\n",
       " 'a6': 8,\n",
       " 'a7': 9,\n",
       " 'a8': 10,\n",
       " 'b1': 11,\n",
       " 'b2': 12,\n",
       " 'b3': 13,\n",
       " 'b4': 14,\n",
       " 'b5': 15,\n",
       " 'b6': 16,\n",
       " 'b7': 17,\n",
       " 'b8': 18,\n",
       " 'c1': 19,\n",
       " 'c2': 20,\n",
       " 'c3': 21,\n",
       " 'c4': 22,\n",
       " 'c5': 23,\n",
       " 'c6': 24,\n",
       " 'c7': 25,\n",
       " 'c8': 26,\n",
       " 'd1': 27,\n",
       " 'd2': 28,\n",
       " 'd3': 29,\n",
       " 'd6': 30,\n",
       " 'd7': 31,\n",
       " 'd8': 32,\n",
       " 'e1': 33,\n",
       " 'e2': 34,\n",
       " 'e3': 35,\n",
       " 'e6': 36,\n",
       " 'e7': 37,\n",
       " 'e8': 38,\n",
       " 'f1': 39,\n",
       " 'f2': 40,\n",
       " 'f3': 41,\n",
       " 'f4': 42,\n",
       " 'f5': 43,\n",
       " 'f6': 44,\n",
       " 'f7': 45,\n",
       " 'f8': 46,\n",
       " 'g1': 47,\n",
       " 'g2': 48,\n",
       " 'g3': 49,\n",
       " 'g4': 50,\n",
       " 'g5': 51,\n",
       " 'g6': 52,\n",
       " 'g7': 53,\n",
       " 'g8': 54,\n",
       " 'h1': 55,\n",
       " 'h2': 56,\n",
       " 'h3': 57,\n",
       " 'h4': 58,\n",
       " 'h5': 59,\n",
       " 'h6': 60,\n",
       " 'h7': 61,\n",
       " 'h8': 62}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T20:16:04.317861Z",
     "start_time": "2025-09-28T20:16:04.312791Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = build_tokenizer(vocab)",
   "id": "6c75128573ba85c2",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T20:16:39.562255Z",
     "start_time": "2025-09-28T20:16:39.557580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Encode a sequence of moves\n",
    "text = \"<pad> <pad> a1 e2 h8\"\n",
    "ids = tokenizer.encode(text)\n",
    "tensor = torch.tensor(ids, dtype=torch.long)"
   ],
   "id": "cfcb244a206fc4bf",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T20:16:40.372221Z",
     "start_time": "2025-09-28T20:16:40.366210Z"
    }
   },
   "cell_type": "code",
   "source": "tensor",
   "id": "621840a0483dec78",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  3, 34, 62])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "193ce33cbb97d28e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
